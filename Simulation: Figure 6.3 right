# Balanced treatment, 20-dimensional, complex linear CATE

set.seed(1)

# VS function
varselection <- function(eX, d, n.sample, n.test, n.killvar){
  
  ################################################################################################
  # Data Preparations
  ################################################################################################
  
  # features and noise
  n <- n.sample + n.test
  S <- genPositiveDefMat("c-vine",dim=d)
  X <- rmnorm(n,varcov=S$Sigma)
  
  noise0 <- rnorm(n,0,1)
  noise1 <- rnorm(n,0,1)
  
  # response functions
  betaC <- runif(n = 3, min = 0, max = 7)
  CATE <- X[,1:3] %*% betaC
  beta <- runif(n = d, min = -5, max = 5)
  mu0 <- X %*% beta # true response function under control
  mu1 <- mu0 + CATE # true response function under treatment
  
  # potential outcomes
  Y0 <- mu0 + noise0
  Y1 <- mu1 + noise1
  
  # data preparations
  data <- data.frame(X,Y0,Y1, CATE)
  index.train <- 1:n.sample
  data.train <- data[index.train,]
  data.test <- data[-index.train,]
  index <- sample(1:n.sample, n.sample*eX)
  data.contr <- data.train[-index,]
  data.treat <- data.train[index,]
  
  ################################################################################################
  # X-Learner RF with automatic Variable Selection
  ################################################################################################
  
  # estimated response function under control and treatment
  mu0.hat.RF <- randomForest(data.contr$Y0~., data = data.contr[,1:d])
  mu1.hat.RF <- randomForest(data.treat$Y1~., data = data.treat[,1:d])
  
  # imputed treatment effects
  mu0X1.pred.RF <- predict(mu0.hat.RF, newdata = data.treat)
  mu1X0.pred.RF <- predict(mu1.hat.RF, newdata = data.contr)
  D0.RF <- mu1X0.pred.RF - data.contr$Y0
  D1.RF <- data.treat$Y1 - mu0X1.pred.RF
  
  data.contr.VS <- data.contr
  data.treat.VS <- data.treat
  d.VS <- d
  
  for (k in 1:n.killvar) {
    
    # CATE estimates
    tau0.hat.RF <- randomForest(D0.RF~., data = data.contr.VS[,1:d.VS], importance=TRUE)
    tau1.hat.RF <- randomForest(D1.RF~., data = data.treat.VS[,1:d.VS], importance=TRUE)
    
    # evaluate feature with lowest IncMSE of both models
    min.D0 <- names(which.min(importance(tau0.hat.RF)[,1]))
    min.D1 <- names(which.min(importance(tau1.hat.RF)[,1]))
    
    # choose less influential feature
    val.D0 <- importance(tau0.hat.RF)[min.D0,1] + importance(tau1.hat.RF)[min.D0,1]
    val.D1 <- importance(tau0.hat.RF)[min.D1,1] + importance(tau1.hat.RF)[min.D1,1]
    choose <- ifelse(val.D0>=val.D1,min.D0,min.D1)
    index <- which(names(data.contr.VS) == choose)
    
    data.contr.VS <- data.contr.VS[,-index]
    data.treat.VS <- data.treat.VS[,-index]
    d.VS <- d.VS-1
    
  }
  
  var.selection <- names(data.contr.VS[,1:d.VS])
  
  return(var.selection)
}

######################################################################################
# Initialisation
######################################################################################

library(foreach)
library(doParallel)

eX <- 0.5 # propensity score
d <- 20 # number of covariates X_i
n.test <- 1000 # number of test observations
n.factor <- 1000 # number of train observations
n.tausend <- c(3, 4, 5, 6, 7, 8, 9, 10, 15, 20)
n.killvar <- d/2 # number of variables that should be excluded by automatic VS

VAR.COUNTS <- matrix(NA, ncol = length(n.tausend), nrow = 3) # second argument is number of dependent features
old <- Sys.time() # get start time

for (i in 1:length(n.tausend)) {
  
  registerDoParallel(88) # set number of cores for parallel computation
  
  n.sample <- n.factor*n.tausend[i] # number of observations
  
  # repeat for certain training size
  VAR.SEL <- foreach(j=1:88, .packages = c("clusterGeneration", "mnormt", "randomForest"), .combine = cbind) %dopar% {
    varselection(eX, d, n.sample, n.test, n.killvar)
  }
  
  # ratio of model still containing dependend variables
  count.X1 <- sum(VAR.SEL=="X1") * (100/88)
  count.X2 <- sum(VAR.SEL=="X2") * (100/88)
  count.X3 <- sum(VAR.SEL=="X3") * (100/88)
  
  VAR.COUNTS[,i] <- c(count.X1, count.X2, count.X3)

  new <- Sys.time() - old # calculate difference
  print(i)
  print(VAR.COUNTS[,i])
  print(new) # print in nice format
  
}

VAR.COUNTS

# plot results
par(mfrow=c(1,1))
plot(n.tausend, VAR.COUNTS[1,], pch=1, col="red", ylim = c(0,100.1)) #X1
plot(n.tausend, VAR.COUNTS[1,], pch=1, col="red") #X1

plot(n.tausend, VAR.COUNTS[2,], pch=3, col="blue", ylim = c(0,100.1)) #X2
plot(n.tausend, VAR.COUNTS[2,], pch=3, col="blue") #X2

plot(n.tausend, VAR.COUNTS[3,], pch=0, col="forestgreen", ylim = c(0,100.1)) #X3
plot(n.tausend, VAR.COUNTS[3,], pch=0, col="forestgreen") #X3

par(mfrow=c(1,1))
plot(n.tausend, VAR.COUNTS[1,], pch=1, bty="n",las=1, ann=F, col="red", ylim = c(0,100.1)) #X1
points(n.tausend, VAR.COUNTS[2,], pch=3, col="blue") #X2
points(n.tausend, VAR.COUNTS[3,], pch=0, col="forestgreen") #X3
mtext("Training Size in 1000", side=1, line=3, las=1)
mtext("Variable Selection in %", side=2, line=3, las=3)

par(mfrow=c(1,1))
plot(n.tausend, VAR.COUNTS[1,], pch=1, bty="n",las=1, ann=F, col="red", ylim = c(min(VAR.COUNTS),max(VAR.COUNTS))) #X1
points(n.tausend, VAR.COUNTS[2,], pch=3, col="blue") #X2
points(n.tausend, VAR.COUNTS[3,], pch=0, col="forestgreen") #X3
mtext("Training Size in 1000", side=1, line=3, las=1)
mtext("Variable Selection in %", side=2, line=3, las=3)

par(mfrow=c(1,1))
plot(n.tausend, VAR.COUNTS[1,], pch=1, bty="n",las=1, ann=F, col="red", ylim = c(0,100.1)) #X1
points(n.tausend, VAR.COUNTS[2,], pch=3, col="blue") #X2
points(n.tausend, VAR.COUNTS[3,], pch=0, col="forestgreen") #X3
mtext("Training Size in 1000", side=1, line=3, las=1)
mtext("Variable Selection in %", side=2, line=3, las=3)

par(mfrow=c(1,1))
plot(n.tausend, VAR.COUNTS[1,], pch=1, bty="n",las=1, ann=F, col="red", ylim = c(min(VAR.COUNTS),max(VAR.COUNTS))) #X1
points(n.tausend, VAR.COUNTS[2,], pch=3, col="blue") #X2
points(n.tausend, VAR.COUNTS[3,], pch=0, col="forestgreen") #X3
mtext("Training Size in 1000", side=1, line=3, las=1)
mtext("Variable Selection in %", side=2, line=3, las=3)
