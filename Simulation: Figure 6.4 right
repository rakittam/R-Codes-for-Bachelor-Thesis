# Balanced treatment, 20-dimensional, complex linear CATE

set.seed(1)

# VS function
varselection <- function(eX, d, n.sample, n.test, K){
  
  ################################################################################################
  # Data Preparations
  ################################################################################################
  
  # features and noise
  n <- n.sample + n.test
  S <- genPositiveDefMat("c-vine",dim=d)
  X <- rmnorm(n,varcov=S$Sigma)
  
  noise0 <- rnorm(n,0,1)
  noise1 <- rnorm(n,0,1)
  
  # response functions
  betaC <- runif(n = 4, min = 20, max = 30)
  CATE <- betaC[1] * cos(betaC[2] * X[,1])^2  + betaC[3] * X[,2] + X[,2] * X[,3] + betaC[4] * X[,4] - X[,4]*X[,5]^2 # true CATE
  beta <- runif(n = d, min = 5, max = 10)
  mu0 <- X %*% beta # true response function under control
  mu1 <- mu0 + CATE # true response function under treatment
  
  # potential outcomes
  Y0 <- mu0 + noise0
  Y1 <- mu1 + noise1
  
  # data preparations
  data <- data.frame(X,Y0,Y1, CATE)
  index.train <- 1:n.sample
  data.train <- data[index.train,]
  data.test <- data[-index.train,]
  index <- sample(1:n.sample, n.sample*eX)
  data.contr <- data.train[-index,]
  data.treat <- data.train[index,]
  
  ################################################################################################
  # X-Learner RF with automatic Variable Selection
  ################################################################################################
  
  # estimated response function under control and treatment
  mu0.hat.RF <- randomForest(data.contr$Y0~., data = data.contr[,1:d])
  mu1.hat.RF <- randomForest(data.treat$Y1~., data = data.treat[,1:d])
  
  # imputed treatment effects
  mu0X1.pred.RF <- predict(mu0.hat.RF, newdata = data.treat)
  mu1X0.pred.RF <- predict(mu1.hat.RF, newdata = data.contr)
  D0.RF <- mu1X0.pred.RF - data.contr$Y0
  D1.RF <- data.treat$Y1 - mu0X1.pred.RF
  
  data.contr.VS <- data.contr
  data.treat.VS <- data.treat
  d.VS <- d
  
  var.selection <- matrix(NA, nrow = K + 1, ncol = 5)
  
  var.selection[1,] <- c(1,1,1,1,1)
  
  for (k in 1:K) {
    
    # CATE estimates
    tau0.hat.RF <- randomForest(D0.RF~., data = data.contr.VS[,1:d.VS], importance=TRUE)
    tau1.hat.RF <- randomForest(D1.RF~., data = data.treat.VS[,1:d.VS], importance=TRUE)
    
    # evaluate feature with lowest IncMSE of both models
    min.D0 <- names(which.min(importance(tau0.hat.RF)[,1]))
    min.D1 <- names(which.min(importance(tau1.hat.RF)[,1]))
    
    # choose less influential feature
    val.D0 <- importance(tau0.hat.RF)[min.D0,1] + importance(tau1.hat.RF)[min.D0,1]
    val.D1 <- importance(tau0.hat.RF)[min.D1,1] + importance(tau1.hat.RF)[min.D1,1]
    choose <- ifelse(val.D0>=val.D1,min.D0,min.D1)
    index <- which(names(data.contr.VS) == choose)
    
    data.contr.VS <- data.contr.VS[,-index]
    data.treat.VS <- data.treat.VS[,-index]
    d.VS <- d.VS-1
    
    chosenV <- names(data.contr.VS[,1:d.VS])
    
    a <- "X1" %in% chosenV
    b <- "X2" %in% chosenV
    c <- "X3" %in% chosenV
    d <- "X4" %in% chosenV
    e <- "X5" %in% chosenV
    
    var.selection[k+1,] <- c(a,b,c,d,e)
  }
  
  return(var.selection)
}

######################################################################################
# Initialisation
######################################################################################

library(foreach)
library(doParallel)

eX <- 0.5 # propensity score
d <- 100 # number of covariates X_i
n.test <- 1000 # number of test observations
n.sample <- 20000 # number of train observations
K <- d-5 # number of variables that should be excluded by automatic VS

C <- 88 # number of cores
registerDoParallel(C) # set number of cores for parallel computation

VAR.SEL <- foreach(j=1:C, .packages = c("clusterGeneration", "mnormt", "randomForest")) %dopar% {
  varselection(eX, d, n.sample, n.test, K)
}

sumX1 <- numeric(K+1)
sumX2 <- numeric(K+1)
sumX3 <- numeric(K+1)
sumX4 <- numeric(K+1)
sumX5 <- numeric(K+1)

for (j in 1:(K+1)) {
  for (l in 1:C) {
    
    sumX1[j] <-  sumX1[j] + VAR.SEL[[l]][j,1]
    sumX2[j] <-  sumX2[j] + VAR.SEL[[l]][j,2]
    sumX3[j] <-  sumX3[j] + VAR.SEL[[l]][j,3]
    sumX4[j] <-  sumX4[j] + VAR.SEL[[l]][j,4]
    sumX5[j] <-  sumX5[j] + VAR.SEL[[l]][j,5]
    
  }
}

sumX1 <- sumX1 * (100/C)
sumX2 <- sumX2 * (100/C)
sumX3 <- sumX3 * (100/C)
sumX4 <- sumX4 * (100/C)
sumX5 <- sumX5 * (100/C)

sumX1
sumX2
sumX3
sumX4
sumX5

# plot results
par(mfrow=c(1,1))
plot(0:K, sumX1, pch=1, col="red", ylim = c(0,100.1)) #X1
plot(0:K, sumX1, pch=1, col="red") #X1

plot(0:K, sumX2, pch=3, col="blue", ylim = c(0,100.1)) #X2
plot(0:K, sumX2, pch=3, col="blue") #X2

plot(0:K, sumX3, pch=0, col="forestgreen", ylim = c(0,100.1)) #X3
plot(0:K, sumX3, pch=0, col="forestgreen") #X3

plot(0:K, sumX4, pch=2, col="orange", ylim = c(0,100.1)) #X4
plot(0:K, sumX4, pch=2, col="orange") #X4

plot(0:K, sumX5, pch=4, col="black", ylim = c(0,100.1)) #X5
plot(0:K, sumX5, pch=4, col="black") #X5

par(mfrow=c(1,1))
plot(0:K, sumX1, pch=1, bty="n",las=1, ann=F, col="red", ylim = c(0,100.1)) #X1
points(0:K, sumX2, pch=3, col="blue") #X2
points(0:K, sumX3, pch=0, col="forestgreen") #X3
points(0:K, sumX4, pch=2, col="orange") #X4
points(0:K, sumX5, pch=4, col="black") #X5
mtext("Number of eliminated features K", side=1, line=3, las=1)
mtext("Variable Selection in %", side=2, line=3, las=3)

par(mfrow=c(1,1))
plot(0:K, sumX1, pch=1, bty="n",las=1, ann=F, col="red",xaxt = 'n', ylim = c(0,100.1)) #X1
points(0:K, sumX2, pch=3, col="blue") #X2
points(0:K, sumX3, pch=0, col="forestgreen") #X3
points(0:K, sumX4, pch=2, col="orange") #X4
points(0:K, sumX5, pch=4, col="black") #X5
mtext("Number of eliminated features K", side=1, line=3, las=1)
mtext("Variable Selection in %", side=2, line=3, las=3)

axis(1, at=c(0,20,40,60,80,95))

par(mfrow=c(1,1))
plot(0:K, sumX1, pch=1, bty="n",las=1, ann=F, col="red", ylim = c(min(c(sumX1,sumX2,sumX3)),max(c(sumX1,sumX2,sumX3)))) #X1
points(0:K, sumX2, pch=3, col="blue") #X2
points(0:K, sumX3, pch=0, col="forestgreen") #X3
points(0:K, sumX4, pch=2, col="orange") #X4
points(0:K, sumX5, pch=4, col="black") #X5
mtext("Number of eliminated features K", side=1, line=3, las=1)
mtext("Variable Selection in %", side=2, line=3, las=3)

par(mfrow=c(1,1))
plot(0:K, sumX1, pch=1, bty="n",las=1, ann=F, col="red",xaxt = 'n', ylim = c(min(c(sumX1,sumX2,sumX3)),max(c(sumX1,sumX2,sumX3)))) #X1
points(0:K, sumX2, pch=3, col="blue") #X2
points(0:K, sumX3, pch=0, col="forestgreen") #X3
points(0:K, sumX4, pch=2, col="orange") #X4
points(0:K, sumX5, pch=4, col="black") #X5
mtext("Number of eliminated features K", side=1, line=3, las=1)
mtext("Variable Selection in %", side=2, line=3, las=3)

axis(1, at=c(0,20,40,60,80,95))



par(mfrow=c(1,1))
plot(0:K, sumX1, pch=1, bty="n",las=1, ann=F, col="red", ylim = c(0,100.1)) #X1
points(0:K, sumX2, pch=3, col="blue") #X2
points(0:K, sumX3, pch=0, col="forestgreen") #X3
points(0:K, sumX4, pch=2, col="orange") #X4
points(0:K, sumX5, pch=4, col="black") #X5
mtext("Number of eliminated features K", side=1, line=3, las=1)
mtext("Variable Selection in %", side=2, line=3, las=3)

par(mfrow=c(1,1))
plot(0:K, sumX1, pch=1, bty="n",las=1, ann=F, col="red",xaxt = 'n', ylim = c(0,100.1)) #X1
points(0:K, sumX2, pch=3, col="blue") #X2
points(0:K, sumX3, pch=0, col="forestgreen") #X3
points(0:K, sumX4, pch=2, col="orange") #X4
points(0:K, sumX5, pch=4, col="black") #X5
mtext("Number of eliminated features K", side=1, line=3, las=1)
mtext("Variable Selection in %", side=2, line=3, las=3)

axis(1, at=c(0,20,40,60,80,95))



par(mfrow=c(1,1))
plot(0:K, sumX1, pch=1, bty="n",las=1, ann=F, col="red", ylim = c(min(c(sumX1,sumX2,sumX3)),max(c(sumX1,sumX2,sumX3)))) #X1
points(0:K, sumX2, pch=3, col="blue") #X2
points(0:K, sumX3, pch=0, col="forestgreen") #X3
points(0:K, sumX4, pch=2, col="orange") #X4
points(0:K, sumX5, pch=4, col="black") #X5
mtext("Number of eliminated features K", side=1, line=3, las=1)
mtext("Variable Selection in %", side=2, line=3, las=3)

par(mfrow=c(1,1))
plot(0:K, sumX1, pch=1, bty="n",las=1, ann=F, col="red",xaxt = 'n', ylim = c(min(c(sumX1,sumX2,sumX3)),max(c(sumX1,sumX2,sumX3)))) #X1
points(0:K, sumX2, pch=3, col="blue") #X2
points(0:K, sumX3, pch=0, col="forestgreen") #X3
points(0:K, sumX4, pch=2, col="orange") #X4
points(0:K, sumX5, pch=4, col="black") #X5
mtext("Number of eliminated features K", side=1, line=3, las=1)
mtext("Variable Selection in %", side=2, line=3, las=3)

axis(1, at=c(0,20,40,60,80,95))
